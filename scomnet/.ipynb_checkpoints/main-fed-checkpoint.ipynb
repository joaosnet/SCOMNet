{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e63d0c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "from typing import Callable, Dict, List, Tuple\n",
    "\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69050a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1):       \n",
    "    list_set = set(list1) \n",
    "    unique_list = (list(list_set)) \n",
    "    unique_list.sort()\n",
    "    return unique_list\n",
    "\n",
    "def create_userids( df ):\n",
    "    array = df.values\n",
    "    y = array[:, -1]\n",
    "    return unique( y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d0560ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df):\n",
    "    train_X = df.iloc[:, :384].values\n",
    "    le = LabelEncoder()\n",
    "    df['user'] = le.fit_transform(df['user'])\n",
    "    train_y = to_categorical(df['user']).astype(int)    \n",
    "    return train_X, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35a0e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    number_of_clients = 10\n",
    "    train_X, train_y = load_data()\n",
    "    train_client_data, train_data = create_uniform_dataset(train_X, train_y, number_of_clients)\n",
    "    return train_client_data, train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e8c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uniform_dataset(\n",
    "    X: np.ndarray, y: np.ndarray, number_of_clients: int\n",
    ") -> Tuple[Dict, tff.simulation.ClientData]:\n",
    "    \"\"\"Function distributes the data equally such that each client holds equal amounts of each class.\n",
    "    Args:\n",
    "        X (np.ndarray): Input.\\n\n",
    "        y (np.ndarray): Output.\\n\n",
    "        number_of_clients (int): Number of clients.\\n\n",
    "    Returns:\n",
    "        [Dict, tff.simulation.ClientData]: A dictionary and a tensorflow federated dataset containing the distributed dataset.\n",
    "    \"\"\"\n",
    "    clients_data = {f\"client_{i}\": [[], []] for i in range(1, number_of_clients + 1)}\n",
    "    for i in range(len(X)):\n",
    "        clients_data[f\"client_{(i%number_of_clients)+1}\"][0].append(X[i])\n",
    "        clients_data[f\"client_{(i%number_of_clients)+1}\"][1].append(y[i])\n",
    "\n",
    "    return clients_data, create_tff_dataset(clients_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14233291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tff_dataset(clients_data: Dict) -> tff.simulation.ClientData:\n",
    "    \"\"\"Function converts dictionary to tensorflow federated dataset.\n",
    "    Args:\n",
    "        clients_data (Dict): Inputs.\n",
    "    Returns:\n",
    "        tff.simulation.ClientData: Returns federated data distribution.\n",
    "    \"\"\"\n",
    "    client_dataset = collections.OrderedDict()\n",
    "\n",
    "    for client in clients_data:\n",
    "        data = collections.OrderedDict(\n",
    "            (\n",
    "                (\"label\", np.array(clients_data[client][1], dtype=np.int32)),\n",
    "                (\"datapoints\", np.array(clients_data[client][0], dtype=np.float32)),\n",
    "            )\n",
    "        )\n",
    "        client_dataset[client] = data\n",
    "\n",
    "    return tff.simulation.FromTensorSlicesClientData(client_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0c9a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    screens = ['Focus', 'Mathisis', 'Memoria', 'Reacton', 'Speedy']\n",
    "    screens_code = ['1', '2', '3', '4', '5']\n",
    "\n",
    "    base_path = \"C:/Users/SouthSystem/Federated Learning/DataBioCom/data\"\n",
    "    phone_accel_file_paths = []\n",
    "\n",
    "    for directories, subdirectories, files in os.walk(base_path):\n",
    "        for filename in files:\n",
    "            if \"accel\" in filename:\n",
    "                phone_accel_file_paths.append(f\"{base_path}/accel/{filename}\")\n",
    "\n",
    "    data = pd.concat(map(pd.read_csv, phone_accel_file_paths))\n",
    "    users = data['player_id'].unique()\n",
    "    \n",
    "    train_set, user_list = split_data(data, users)\n",
    "    train_set = np.array([np.array(x) for x in train_set]) \n",
    "    train_set_join = train_set.reshape(train_set.shape[0], 384)\n",
    "    data_join = pd.DataFrame(train_set_join)\n",
    "    data_join['user'] = user_list\n",
    "    \n",
    "    train_X, train_y = split_dataframe(data_join)\n",
    "    \n",
    "    return train_X, train_y\n",
    "\n",
    "def split_data(data, users):\n",
    "    user_list = []\n",
    "    train = []\n",
    "    frame_size = 128\n",
    "    step = 50\n",
    "\n",
    "    for user in users:\n",
    "        data_user = data[data['player_id']==user]  \n",
    "        data_user = data_user.iloc[:,[0,1,2]]\n",
    "        for w in range(0, data_user.shape[0] - frame_size, step):\n",
    "            end = w + frame_size        \n",
    "            frame = data_user.iloc[w:end,[0, 1, 2]]        \n",
    "            train.append(frame)\n",
    "            user_list.append(user)\n",
    "\n",
    "    return train, user_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f298d3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.14604597,  0.80252016,  0.58662611, ..., -0.01514189,\n",
       "          0.77321327,  0.66184711],\n",
       "        [ 0.        ,  0.77125949,  0.67503524, ..., -0.10843547,\n",
       "          0.8078931 ,  0.97250009],\n",
       "        [ 0.02344551,  0.77809781,  0.65500885, ...,  0.02149171,\n",
       "          0.61984062,  0.78005153],\n",
       "        ...,\n",
       "        [-0.03955078, -0.6050415 , -0.78927612, ..., -0.05117798,\n",
       "         -0.60906982, -0.78384399],\n",
       "        [-0.04751587, -0.60830688, -0.78411865, ..., -0.04589844,\n",
       "         -0.6043396 , -0.78945923],\n",
       "        [-0.05181885, -0.60850525, -0.73361206, ..., -0.04301453,\n",
       "         -0.60502625, -0.79290771]]),\n",
       " array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 0, ..., 0, 0, 1]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ed0fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
